{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        path = os.path.join(dirname, filename)\n",
    "        \n",
    "\n",
    "# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-ded54d4703f4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'path' is not defined"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(path)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-f89cc58313c4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompany_profile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompany_profile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'int'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_salary_range'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msalary_range\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'int'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df.company_profile = df.company_profile.notnull().astype('int')\n",
    "df['has_salary_range'] = df.salary_range.notnull().astype('int') \n",
    "\n",
    "f_df = df[df.fraudulent == True]\n",
    "r_df = df[df.fraudulent == False]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "def feature_extraction(column, normalize):\n",
    "    real = round(((r_df[column].sum() / len(r_df)) * 100), 2)\n",
    "    fake = round(((f_df[column].sum() / len(f_df)) * 100), 2)\n",
    "    print(f'Feature : {column}  real jobs percentage: {real}  fake jobs percentage: {fake}')\n",
    "    x =  pd.DataFrame({\"real_jobs\": real, \"fake_jobs\" : fake}, index = [0])\n",
    "    sns.barplot(data = x, label = column)\n",
    "    \n",
    "    if normalize is True:\n",
    "        plt.yticks(np.arange(0,110, 10))\n",
    "    \n",
    "feature_extraction(column = \"has_company_logo\", normalize= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extraction(column = \"telecommuting\", normalize= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extraction(column = \"has_questions\", normalize= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extraction(column = \"company_profile\", normalize= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extraction(column = \"has_salary_range\", normalize= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "irrelevant_columns = ['job_id', 'location', 'title', 'department', 'salary_range']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# r_df = r_df.fillna('NO VALUE')\n",
    "# f_df = f_df.fillna('NO VALUE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_table(column_name):\n",
    "    r_func_df = pd.DataFrame(r_df[column_name].value_counts())\n",
    "    r_func_df['%_real_jobs'] = (r_func_df[column_name] / len(r_df)) * 100\n",
    "    r_func_df = r_func_df.drop(column_name, axis= 1)\n",
    "\n",
    "\n",
    "    f_func_df = pd.DataFrame(f_df[column_name].value_counts())\n",
    "    f_func_df['%_fake_jobs'] = (f_func_df[column_name] / len(f_df)) * 100\n",
    "    f_func_df = f_func_df.drop(column_name, axis= 1)\n",
    "\n",
    "    job_func_df = r_func_df.join(f_func_df)\n",
    "    job_func_df['diff'] = abs(r_func_df['%_real_jobs'] - f_func_df['%_fake_jobs'] )\n",
    "    print(job_func_df.sort_values(by= 'diff', ascending= False))\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_table(column_name = 'function')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_table(column_name = 'industry')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_table(column_name = 'required_experience')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_table(column_name = 'required_education')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_table(column_name = 'title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_table(column_name = 'employment_type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "irrelevant_columns = ['job_id', 'location', 'title', 'department', 'salary_range' ]\n",
    "df.drop(irrelevant_columns, axis =1 , inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.required_education = df.required_education.fillna(0)\n",
    "dict = {0:0}\n",
    "a = 5\n",
    "for i in df.required_education.unique():\n",
    "    dict.update({i: a})\n",
    "    a = a+1\n",
    "\n",
    "df.required_education = df.required_education.map(dict)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_columns = ['company_profile', 'telecommuting', 'has_company_logo', 'has_questions', 'has_salary_range', 'fraudulent', 'required_education']\n",
    "binary_df = df[relevant_columns]\n",
    "binary_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category = FutureWarning) \n",
    "\n",
    "\n",
    "\n",
    "features = binary_df.drop('fraudulent', axis=1)\n",
    "labels = binary_df['fraudulent']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size = 0.4, random_state = 42)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size = 0.5, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier()\n",
    "\n",
    "scores = cross_val_score(rf, X_train, y_train, cv = 5)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " def print_results(results):\n",
    "    print(f'BEST PARAMS: {results.best_params_}')\n",
    "    \n",
    "    means = results.cv_results_['mean_test_score']\n",
    "    stds = results.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, results.cv_results_['params']):\n",
    "        print(f'{round(mean, 3)} (+/-{std + 2, 3}) for {params}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier()\n",
    "parameters = {\n",
    "    'n_estimators' : [5, 50, 100],\n",
    "    'max_depth': [2, 10, 20, None]\n",
    "}\n",
    "\n",
    "cv = GridSearchCV(rf, parameters, cv = 5)\n",
    "cv.fit(X_train, y_train)\n",
    "\n",
    "print_results(cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf1 = RandomForestClassifier(n_estimators= 50, max_depth= 2)\n",
    "rf1.fit(X_train, y_train)\n",
    "\n",
    "rf2 = RandomForestClassifier(n_estimators= 100, max_depth= 20)\n",
    "rf2.fit(X_train, y_train)\n",
    "\n",
    "rf3 = RandomForestClassifier(n_estimators= 103, max_depth= 10)\n",
    "rf3.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "for mdl in [rf1, rf2, rf3]:\n",
    "    y_pred = mdl.predict(X_val)\n",
    "    accuracy = round(accuracy_score(y_val, y_pred),3)\n",
    "    precision = round(precision_score(y_val, y_pred),3)\n",
    "    recall = round(recall_score(y_val, y_pred),3)\n",
    "    print(f'MAX DEPTH: {mdl.max_depth}, # of EST: {mdl.n_estimators}, A: {accuracy}, P: {precision}, R:{recall}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = rf3.predict(X_test)\n",
    "accuracy =  round(accuracy_score(y_test, y_pred),3)\n",
    "precision = round(precision_score(y_test, y_pred),3)\n",
    "recall =    round(recall_score(y_test, y_pred),3)\n",
    "\n",
    "print(f'MAX DEPTH: {rf3.max_depth}, # of EST: {rf3.n_estimators}, A: {accuracy}, P: {precision}, R:{recall}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model\n",
    "'''\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "MOD = RandomForestClassifier() \n",
    "#Implemente RandomSearchCV\n",
    "m_params = { \n",
    "            \"RF\": {\n",
    "                    \"n_estimators\" : np.linspace(2, 500, 500, dtype = \"int\"),  \n",
    "                    \"max_depth\": [5, 20, 30, None], \n",
    "                    \"min_samples_split\": np.linspace(2, 50, 50, dtype = \"int\"),  \n",
    "                    \"max_features\": [\"sqrt\", \"log2\",10, 20, None],\n",
    "                    \"oob_score\": [True],\n",
    "                    \"bootstrap\": [True]\n",
    "                    },\n",
    "            }\n",
    "scoreFunction = {\"recall\": \"recall\", \"precision\": \"precision\"}\n",
    "random_search = RandomizedSearchCV(MOD,\n",
    "                                   param_distributions = m_params['RF'], \n",
    "                                   n_iter = 20,\n",
    "                                   scoring = scoreFunction,               \n",
    "                                   refit = \"recall\",\n",
    "                                   return_train_score = True,\n",
    "                                   random_state = 42,\n",
    "                                   cv = 5)\n",
    "                            #       verbose = 1 + int(log)) \n",
    "\n",
    "#trains and optimizes the model\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "#recover the best model\n",
    "MOD = random_search.best_estimator_\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
