{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        path = os.path.join(dirname, filename)\n        \n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df = pd.read_csv(path)\ndf.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\n\ndf.company_profile = df.company_profile.notnull().astype('int')\ndf['has_salary_range'] = df.salary_range.notnull().astype('int') \n\nf_df = df[df.fraudulent == True]\nr_df = df[df.fraudulent == False]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Feature Extraction","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\ndef feature_extraction(column, normalize):\n    real = round(((r_df[column].sum() / len(r_df)) * 100), 2)\n    fake = round(((f_df[column].sum() / len(f_df)) * 100), 2)\n    print(f'Feature : {column}  real jobs percentage: {real}  fake jobs percentage: {fake}')\n    x =  pd.DataFrame({\"real_jobs\": real, \"fake_jobs\" : fake}, index = [0])\n    sns.barplot(data = x, label = column)\n    \n    if normalize is True:\n        plt.yticks(np.arange(0,110, 10))\n    \nfeature_extraction(column = \"has_company_logo\", normalize= True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"feature_extraction(column = \"telecommuting\", normalize= False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"feature_extraction(column = \"has_questions\", normalize= False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"feature_extraction(column = \"company_profile\", normalize= True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"feature_extraction(column = \"has_salary_range\", normalize= True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"irrelevant_columns = ['job_id', 'location', 'title', 'department', 'salary_range']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# r_df = r_df.fillna('NO VALUE')\n# f_df = f_df.fillna('NO VALUE')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def feature_table(column_name):\n    r_func_df = pd.DataFrame(r_df[column_name].value_counts())\n    r_func_df['%_real_jobs'] = (r_func_df[column_name] / len(r_df)) * 100\n    r_func_df = r_func_df.drop(column_name, axis= 1)\n\n\n    f_func_df = pd.DataFrame(f_df[column_name].value_counts())\n    f_func_df['%_fake_jobs'] = (f_func_df[column_name] / len(f_df)) * 100\n    f_func_df = f_func_df.drop(column_name, axis= 1)\n\n    job_func_df = r_func_df.join(f_func_df)\n    job_func_df['diff'] = abs(r_func_df['%_real_jobs'] - f_func_df['%_fake_jobs'] )\n    print(job_func_df.sort_values(by= 'diff', ascending= False))\n    \n    \n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"feature_table(column_name = 'function')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"feature_table(column_name = 'industry')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"feature_table(column_name = 'required_experience')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"feature_table(column_name = 'required_education')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"feature_table(column_name = 'title')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"feature_table(column_name = 'employment_type')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"irrelevant_columns = ['job_id', 'location', 'title', 'department', 'salary_range' ]\ndf.drop(irrelevant_columns, axis =1 , inplace= True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.required_education = df.required_education.fillna(0)\ndict = {0:0}\na = 5\nfor i in df.required_education.unique():\n    dict.update({i: a})\n    a = a+1\n\ndf.required_education = df.required_education.map(dict)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"relevant_columns = ['company_profile', 'telecommuting', 'has_company_logo', 'has_questions', 'has_salary_range', 'fraudulent', 'required_education']\nbinary_df = df[relevant_columns]\nbinary_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score\nimport warnings\n\nwarnings.filterwarnings(\"ignore\", category = FutureWarning) \n\n\n\nfeatures = binary_df.drop('fraudulent', axis=1)\nlabels = binary_df['fraudulent']\n\nX_train, X_test, y_train, y_test = train_test_split(features, labels, test_size = 0.4, random_state = 42)\nX_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size = 0.5, random_state = 42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rf = RandomForestClassifier()\n\nscores = cross_val_score(rf, X_train, y_train, cv = 5)\nscores","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":" def print_results(results):\n    print(f'BEST PARAMS: {results.best_params_}')\n    \n    means = results.cv_results_['mean_test_score']\n    stds = results.cv_results_['std_test_score']\n    for mean, std, params in zip(means, stds, results.cv_results_['params']):\n        print(f'{round(mean, 3)} (+/-{std + 2, 3}) for {params}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rf = RandomForestClassifier()\nparameters = {\n    'n_estimators' : [5, 50, 100],\n    'max_depth': [2, 10, 20, None]\n}\n\ncv = GridSearchCV(rf, parameters, cv = 5)\ncv.fit(X_train, y_train)\n\nprint_results(cv)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rf1 = RandomForestClassifier(n_estimators= 50, max_depth= 2)\nrf1.fit(X_train, y_train)\n\nrf2 = RandomForestClassifier(n_estimators= 100, max_depth= 20)\nrf2.fit(X_train, y_train)\n\nrf3 = RandomForestClassifier(n_estimators= 103, max_depth= 10)\nrf3.fit(X_train, y_train)\n\n\nfor mdl in [rf1, rf2, rf3]:\n    y_pred = mdl.predict(X_val)\n    accuracy = round(accuracy_score(y_val, y_pred),3)\n    precision = round(precision_score(y_val, y_pred),3)\n    recall = round(recall_score(y_val, y_pred),3)\n    print(f'MAX DEPTH: {mdl.max_depth}, # of EST: {mdl.n_estimators}, A: {accuracy}, P: {precision}, R:{recall}')\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = rf3.predict(X_test)\naccuracy =  round(accuracy_score(y_test, y_pred),3)\nprecision = round(precision_score(y_test, y_pred),3)\nrecall =    round(recall_score(y_test, y_pred),3)\n\nprint(f'MAX DEPTH: {rf3.max_depth}, # of EST: {rf3.n_estimators}, A: {accuracy}, P: {precision}, R:{recall}')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#model\n'''\nfrom sklearn.model_selection import RandomizedSearchCV\nMOD = RandomForestClassifier() \n#Implemente RandomSearchCV\nm_params = { \n            \"RF\": {\n                    \"n_estimators\" : np.linspace(2, 500, 500, dtype = \"int\"),  \n                    \"max_depth\": [5, 20, 30, None], \n                    \"min_samples_split\": np.linspace(2, 50, 50, dtype = \"int\"),  \n                    \"max_features\": [\"sqrt\", \"log2\",10, 20, None],\n                    \"oob_score\": [True],\n                    \"bootstrap\": [True]\n                    },\n            }\nscoreFunction = {\"recall\": \"recall\", \"precision\": \"precision\"}\nrandom_search = RandomizedSearchCV(MOD,\n                                   param_distributions = m_params['RF'], \n                                   n_iter = 20,\n                                   scoring = scoreFunction,               \n                                   refit = \"recall\",\n                                   return_train_score = True,\n                                   random_state = 42,\n                                   cv = 5)\n                            #       verbose = 1 + int(log)) \n\n#trains and optimizes the model\nrandom_search.fit(X_train, y_train)\n\n#recover the best model\nMOD = random_search.best_estimator_\n'''","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}